{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from csv import reader\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics.pairwise import pairwise_distances, cosine_similarity\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour, RepeatedEditedNearestNeighbours, EditedNearestNeighbours\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "#Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the data frame\n",
    "m,n=data.shape\n",
    "\n",
    "#Select train and labels\n",
    "X = data.iloc[:,1:n]\n",
    "y = data.iloc[:,0]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.5, random_state= 0)\n",
    "\n",
    "\n",
    "df_mean = list()\n",
    "act = np.unique(y)\n",
    "len_act = len(act)\n",
    "\n",
    "for i in act:\n",
    "    A = y_train == i\n",
    "    d = X_train[A]\n",
    "    temp = \"df\"+str(i) \n",
    "    vars()[temp] = d.reset_index(drop=True)\n",
    "    r,c = vars()[temp].shape\n",
    "    X0 = vars()[temp].iloc[:,0:c]\n",
    "    \n",
    "    db_cluster = DBSCAN(eps=.25, min_samples=10).fit(X0)\n",
    "    \n",
    "    X0_aux = pd.DataFrame(X0)\n",
    "    X0_aux['label'] = pd.DataFrame(db_cluster.labels_)\n",
    "    \n",
    "    lab = np.unique(db_cluster.labels_)\n",
    "    \n",
    "    for l in lab:\n",
    "        mean_aux = X0_aux[X0_aux['label']==l]\n",
    "        mean_cl = np.mean(mean_aux.iloc[:,0:mean_aux.shape[1]-1])\n",
    "        df_mean.append((np.asarray(mean_cl)))\n",
    "\n",
    "df_cl = pd.DataFrame(np.array(df_mean).T)        \n",
    "\n",
    "# Size of the data frame\n",
    "\n",
    "#Xt = data_aux.iloc[:,0:11]\n",
    "m,n = X_train.shape\n",
    "Xt = np.array(X_train)\n",
    "ps = np.array(df_cl).T\n",
    "#ps = np.array(clusters)\n",
    "cm,cn = ps.shape\n",
    "\n",
    "dist = np.empty((m,cm))\n",
    "\n",
    "for w in range(m):\n",
    "    d1 = Xt[w].reshape(1, -1)\n",
    "    for t in range(cm):\n",
    "        dist[w][t] = pairwise_distances(d1,ps[t].reshape(1,-1),'cosine') \n",
    "\n",
    "#Xt = data_aux.iloc[:,0:11]\n",
    "m,n = X_test.shape\n",
    "Xt = np.array(X_test)\n",
    "ps = np.array(df_cl).T\n",
    "#ps = np.array(clusters)\n",
    "cm,cn = ps.shape\n",
    "dist_test = np.empty((m,cm))\n",
    "\n",
    "for w in range(m):\n",
    "    d1 = Xt[w].reshape(1, -1)\n",
    "    for t in range(cm):\n",
    "        dist_test[w][t] = pairwise_distances(d1,ps[t].reshape(1,-1),'cosine') \n",
    "\n",
    "        \n",
    "parameters  = {'C':[.1,1],'gamma':[.1,1]}\n",
    "#smv_dism_data1 = svm.SVC(kernel='rbf', probability = True)\n",
    "smv_dism_data1 = svm.SVC(kernel='rbf', probability = True, class_weight = 'balanced')\n",
    "clf = GridSearchCV(smv_dism_data1, parameters)\n",
    "predicted_data1 = clf.fit(X_train, y_train)\n",
    "#predicted_data1 = smv_dism_data1.fit(X_train, y_train)\n",
    "pred_proba_test = predicted_data1.predict_proba(dist_test)\n",
    "pred_label = predicted_data1.predict(dist_test)\n",
    "rs = recall_score(y_test, pred_label, average='macro') \n",
    "ps = precision_score(y_test, pred_label, average='macro') \n",
    "\n",
    "\n",
    "#### Filter misclassified instances\n",
    "distc=X_test.copy()\n",
    "distc = pd.DataFrame(distc)\n",
    "distc['label'] = pd.DataFrame(y_test)\n",
    "distc['SVM_label'] = pd.DataFrame(pred_label) \n",
    "distc['label_b'] = np.where((distc['label'] == distc['SVM_label']), 1, 0)\n",
    "A = distc['label_b'] == 0 #misclassified\n",
    "d = distc[A]\n",
    "c_class = distc[-A]\n",
    "distc_new = d.reset_index(drop=True)\n",
    "df_cc = c_class.reset_index(drop=True)\n",
    "label_df = distc_new[['label','SVM_label']] \n",
    "\n",
    "x_cnn = distc_new.iloc[:,0:distc_new.shape[1]-3]\n",
    "y_cnn = distc_new.iloc[:,distc_new.shape[1]-3]\n",
    "cnn = CondensedNearestNeighbour(return_indices=True)\n",
    "X_resampled, y_resampled, idx_resampled = cnn.fit_sample(x_cnn, y_cnn)\n",
    "Xcnn = pd.DataFrame(X_resampled)\n",
    "Xcnn['label'] = pd.DataFrame(y_resampled)\n",
    "x_cnn['label'] = y_cnn\n",
    "Xcnn = Xcnn.append(x_cnn)\n",
    "Xsplit = Xcnn.iloc[:,0:Xcnn.shape[1]]\n",
    "ysplit = Xcnn.iloc[:, Xcnn.shape[1]-1]\n",
    "X_train_m, X_test_m, y_train_m, y_test_ = train_test_split(Xsplit,ysplit, test_size=0.2, random_state= 0)\n",
    "\n",
    "#### Create subspaces\n",
    "X_train_m = pd.DataFrame(X_train_m)\n",
    "dist_cl = X_train_m.iloc[:,0:X_train_m.shape[1]-1]\n",
    "db_cluster_sub = DBSCAN(eps= .25, min_samples=10).fit(dist_cl)   \n",
    "X_train_m['cl_label'] = pd.DataFrame(db_cluster_sub.labels_)\n",
    "X_train_m['cl_label'] = np.nan_to_num(np.array(X_train_m['cl_label']))  \n",
    "\n",
    "### Filter subspaces\n",
    "lab_aux =  np.unique(np.array(X_train_m['cl_label']))\n",
    "subspace = list()\n",
    "for lab in lab_aux:\n",
    "    A_aux = X_train_m['cl_label'] == lab\n",
    "    daux = X_train_m[A_aux]\n",
    "    daux = daux.reset_index(drop=True)\n",
    "    if daux.shape[0]>2:\n",
    "        subspace.append(daux)\n",
    "        \n",
    "        \n",
    "rdf = c_class.iloc[:,0:c_class.shape[1]-2]\n",
    "\n",
    "for s in range(len(subspace)):\n",
    "    dfs = subspace[s]\n",
    "    count_class = np.unique(np.array(dfs['label']),return_counts=True)\n",
    "    num_class = count_class[1]\n",
    "    for n in range(len(num_class)):\n",
    "        if num_class[n] < 10:\n",
    "            \n",
    "            class_s = []\n",
    "            class_s.append(count_class[0][n])\n",
    "            svmlab = label_df['label'] == class_s[0]\n",
    "            svm_lab = label_df[svmlab]\n",
    "            false_label = np.unique(svm_lab['SVM_label'])\n",
    "            class_s = np.concatenate((false_label,class_s),axis=0)\n",
    "            \n",
    "\n",
    "            for cf in range(len(class_s)):\n",
    "                tc_df = rdf['label'] == class_s[cf]\n",
    "                tcdfaux = rdf[tc_df]\n",
    "                tcdfaux = tcdfaux.reset_index(drop=True)\n",
    "                if tcdfaux.shape[0] >0 :\n",
    "                    subspace[s] = subspace[s].append(tcdfaux.sample(num_class[n]+6,replace=True))\n",
    "                else:\n",
    "                    tc = pd.DataFrame(X_train)\n",
    "                    tc['label'] = pd.DataFrame(y_train)\n",
    "                    tc_df = tc['label'] == class_s[cf]\n",
    "                    tcdfaux = tc[tc_df]\n",
    "                    tcdfaux = tcdfaux.reset_index(drop=True)\n",
    "                    subspace[s] = subspace[s].append(tcdfaux.sample(num_class[n]+6,replace=True))\n",
    "\n",
    "\n",
    "#Resample with SMOTE Technique + CNN\n",
    "\n",
    "new_subspace = list()\n",
    "for s in range(len(subspace)):\n",
    "    dfs = subspace[s].iloc[:,0:subspace[s].shape[1]-1]\n",
    "    \n",
    "    dfs_x = dfs.iloc[:,0:dfs.shape[1]-1]\n",
    "    dfs_y = dfs.iloc[:, dfs.shape[1]-1]\n",
    "    \n",
    "    sm = SMOTE(ratio = 'auto', random_state=0)\n",
    "    X_res, y_res = sm.fit_sample(dfs_x, dfs_y)\n",
    "    \n",
    "    X_resv = pd.DataFrame(X_res)\n",
    "    X_resv['y_r'] = pd.DataFrame(y_res)\n",
    "    \n",
    "    #new_subspace.append(X_res)\n",
    "    \n",
    "    # Apply Condensed Nearest Neighbours\n",
    "    cnn = CondensedNearestNeighbour(return_indices=True)\n",
    "    X_resampled, y_resampled, idx_resampled = cnn.fit_sample(X_res, y_res)\n",
    "\n",
    "    #Select train and labels\n",
    "    X_resampled = pd.DataFrame(X_resampled)\n",
    "    X_resampled['y_r'] = pd.DataFrame(y_resampled)\n",
    "    X_resv = X_resv.append(X_resampled, ignore_index=True)\n",
    "    new_subspace.append(X_resv)\n",
    "    \n",
    "\n",
    "len_sub = len(new_subspace)\n",
    "proba_dist = list()\n",
    "true_test = list()\n",
    "pred_test = list()\n",
    "proba_dist = list()\n",
    "predlabel = list()\n",
    "classes = list()\n",
    "test_df = pd.DataFrame(X_test_m.iloc[:,0:X_test_m.shape[1]-1])\n",
    "new_sub = list()\n",
    "\n",
    "\n",
    "for l in range(len(new_subspace)):\n",
    "    \n",
    "    df0 = new_subspace[l]\n",
    "    X_aux = df0.iloc[:,0:df0.shape[1]-1]\n",
    "    y_aux = df0.iloc[:,df0.shape[1]-1]\n",
    "       \n",
    "    #SVM   \n",
    "    parameters  = {'C':[.1,1],'gamma':[.1,1]}\n",
    "    #smv_sub = svm.SVC(kernel='rbf', probability = True)\n",
    "    smv_sub = svm.SVC(kernel='rbf', probability = True, class_weight = 'balanced')\n",
    "    clf = GridSearchCV(smv_sub, parameters)\n",
    "    predicted_sub = clf.fit(X_aux, y_aux)\n",
    "    pred_prob_sub = predicted_sub.predict_proba(test_df)\n",
    "    #Save probability distribution\n",
    "    proba_dist.append((pred_prob_sub))\n",
    "    predlabel.append((predicted_sub.predict(test_df)))\n",
    "    #Classes\n",
    "    classes.append((predicted_sub.classes_))\n",
    "\n",
    "    \n",
    "#Ensemble part\n",
    "len_p = len(proba_dist)\n",
    "ensemble = np.zeros((test_df.shape[0],len_p),dtype=int)\n",
    "\n",
    "for num in range(len_p):\n",
    "    class_vec = classes[num]\n",
    "    for row in range(proba_dist[num].shape[0]):\n",
    "        row_max = proba_dist[num][row].max()\n",
    "        id_max = np.argmax(proba_dist[num][row])\n",
    "        ensemble[row][num] = class_vec[id_max]\n",
    "\n",
    "ensemble_pred = np.zeros(test_df.shape[0],dtype=int)\n",
    "\n",
    "for row in range(ensemble.shape[0]):\n",
    "    ensemble_pred[row] = stats.mode(ensemble[row])[0][0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
